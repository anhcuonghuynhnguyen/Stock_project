[2024-06-11 08:16:09,570] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: ELT_to_Data_Warehouse.load_db_to_parquet 2024-06-11T08:15:49.953823+00:00 [queued]>
[2024-06-11 08:16:09,579] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: ELT_to_Data_Warehouse.load_db_to_parquet 2024-06-11T08:15:49.953823+00:00 [queued]>
[2024-06-11 08:16:09,580] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2024-06-11 08:16:09,580] {taskinstance.py:1018} INFO - Starting attempt 1 of 2
[2024-06-11 08:16:09,580] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2024-06-11 08:16:09,595] {taskinstance.py:1038} INFO - Executing <Task(BashOperator): load_db_to_parquet> on 2024-06-11T08:15:49.953823+00:00
[2024-06-11 08:16:09,600] {standard_task_runner.py:51} INFO - Started process 21816 to run task
[2024-06-11 08:16:09,610] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'ELT_to_Data_Warehouse', 'load_db_to_parquet', '2024-06-11T08:15:49.953823+00:00', '--job-id', '133', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/elt_to_dw.py', '--cfg-path', '/tmp/tmpc399w68k']
[2024-06-11 08:16:09,611] {standard_task_runner.py:76} INFO - Job 133: Subtask load_db_to_parquet
[2024-06-11 08:16:09,656] {logging_mixin.py:103} INFO - Running <TaskInstance: ELT_to_Data_Warehouse.load_db_to_parquet 2024-06-11T08:15:49.953823+00:00 [running]> on host etl.us-central1-a.c.data-engineering-stock.internal
[2024-06-11 08:16:09,709] {taskinstance.py:1230} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=ELT_to_Data_Warehouse
AIRFLOW_CTX_TASK_ID=load_db_to_parquet
AIRFLOW_CTX_EXECUTION_DATE=2024-06-11T08:15:49.953823+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-06-11T08:15:49.953823+00:00
[2024-06-11 08:16:09,710] {bash.py:135} INFO - Tmp dir root location: 
 /tmp
[2024-06-11 08:16:09,711] {bash.py:158} INFO - Running command: /bin/python3 /home/anhcu/Project/Stock_project/elt/scripts/load/load_db_to_parquet.py
[2024-06-11 08:16:09,722] {bash.py:169} INFO - Output:
[2024-06-11 08:16:13,103] {bash.py:173} INFO - <class 'pandas.core.frame.DataFrame'>
[2024-06-11 08:16:13,104] {bash.py:173} INFO - RangeIndex: 19706 entries, 0 to 19705
[2024-06-11 08:16:13,104] {bash.py:173} INFO - Data columns (total 12 columns):
[2024-06-11 08:16:13,104] {bash.py:173} INFO -  #   Column                   Non-Null Count  Dtype
[2024-06-11 08:16:13,104] {bash.py:173} INFO - ---  ------                   --------------  -----
[2024-06-11 08:16:13,104] {bash.py:173} INFO -  0   company_name             19706 non-null  object
[2024-06-11 08:16:13,104] {bash.py:173} INFO -  1   company_ticket           19706 non-null  object
[2024-06-11 08:16:13,104] {bash.py:173} INFO -  2   company_is_delisted      19706 non-null  bool
[2024-06-11 08:16:13,104] {bash.py:173} INFO -  3   company_category         19706 non-null  object
[2024-06-11 08:16:13,104] {bash.py:173} INFO -  4   company_currency         19706 non-null  object
[2024-06-11 08:16:13,104] {bash.py:173} INFO -  5   company_location         19706 non-null  object
[2024-06-11 08:16:13,104] {bash.py:173} INFO -  6   company_exchange_name    19706 non-null  object
[2024-06-11 08:16:13,104] {bash.py:173} INFO -  7   company_region_name      19706 non-null  object
[2024-06-11 08:16:13,104] {bash.py:173} INFO -  8   company_industry_name    19706 non-null  object
[2024-06-11 08:16:13,104] {bash.py:173} INFO -  9   company_industry_sector  19706 non-null  object
[2024-06-11 08:16:13,105] {bash.py:173} INFO -  10  company_sic_industry     19706 non-null  object
[2024-06-11 08:16:13,105] {bash.py:173} INFO -  11  company_sic_sector       19706 non-null  object
[2024-06-11 08:16:13,105] {bash.py:173} INFO - dtypes: bool(1), object(11)
[2024-06-11 08:16:13,105] {bash.py:173} INFO - memory usage: 1.7+ MB
[2024-06-11 08:16:13,105] {bash.py:173} INFO - None
[2024-06-11 08:16:13,105] {bash.py:173} INFO - Saved data from database to parquet successfully at /home/anhcu/Project/Stock_project/elt/data/completed/load_db_to_dl/load_db_to_dl_2024_06_11.parquet
[2024-06-11 08:16:13,338] {bash.py:177} INFO - Command exited with return code 0
[2024-06-11 08:16:13,366] {taskinstance.py:1135} INFO - Marking task as SUCCESS. dag_id=ELT_to_Data_Warehouse, task_id=load_db_to_parquet, execution_date=20240611T081549, start_date=20240611T081609, end_date=20240611T081613
[2024-06-11 08:16:13,399] {taskinstance.py:1195} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-11 08:16:13,433] {local_task_job.py:118} INFO - Task exited with return code 0
